{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DoubleHeadMBTI+Big5Pendora (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee50d3eb44984fd68a04dd22d33a765c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e86ae12ffb4948cb8a1af49c38038b47",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a30911b6b054d3ea197ccfcfb8e666f",
              "IPY_MODEL_1f13b86301774ade8fb257047e1800a8",
              "IPY_MODEL_6a50263fbd574ea2af76896a50bbebd2"
            ]
          }
        },
        "e86ae12ffb4948cb8a1af49c38038b47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a30911b6b054d3ea197ccfcfb8e666f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c3813e8a1d24f24acc1af06e4fff0c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be48b471d5504e6daf03b6f2f1ab100b"
          }
        },
        "1f13b86301774ade8fb257047e1800a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d71aad9266fc4425b75399a9cbbe46f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9fd848ed901450b85c96b8659c08797"
          }
        },
        "6a50263fbd574ea2af76896a50bbebd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b68c7b0b6eae4753b864ac1a49da33df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 2.48MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6a23eb688764a18b130408578b10791"
          }
        },
        "8c3813e8a1d24f24acc1af06e4fff0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be48b471d5504e6daf03b6f2f1ab100b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d71aad9266fc4425b75399a9cbbe46f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9fd848ed901450b85c96b8659c08797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b68c7b0b6eae4753b864ac1a49da33df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6a23eb688764a18b130408578b10791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "684ecd4caaed4430a69b0924b37f3ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a65541bc2bd4b6fa6c8f343edaf3648",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_53b411a51b644c619e37132aea1200d5",
              "IPY_MODEL_f645c125488d425ab0632bd56f8d8b19",
              "IPY_MODEL_b67724c74eea46b0bd2194b75e59edbf"
            ]
          }
        },
        "4a65541bc2bd4b6fa6c8f343edaf3648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53b411a51b644c619e37132aea1200d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff2a67fdfb77477696b6050d1cb2683b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b68ded0ff9504f6f97e619f29e5fe965"
          }
        },
        "f645c125488d425ab0632bd56f8d8b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f052a7a7d2264f50bc4b04db140ca1fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3225afb48ca74e34a6a14c4b51bdce77"
          }
        },
        "b67724c74eea46b0bd2194b75e59edbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a607147dd3e4bb1845f233778414d59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 971B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1625ea769b847c684a2772ba589289b"
          }
        },
        "ff2a67fdfb77477696b6050d1cb2683b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b68ded0ff9504f6f97e619f29e5fe965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f052a7a7d2264f50bc4b04db140ca1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3225afb48ca74e34a6a14c4b51bdce77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a607147dd3e4bb1845f233778414d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1625ea769b847c684a2772ba589289b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c19302d49a34749b9d7d010468a3720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0459f1a84bb34665918057e9ebe8ad5b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_376a4576f274439fa80d0945a8dfa418",
              "IPY_MODEL_ae0237a296cb45ec942502b707e47b71",
              "IPY_MODEL_6927c1a2ef9f48dfb90114f1f875fb11"
            ]
          }
        },
        "0459f1a84bb34665918057e9ebe8ad5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "376a4576f274439fa80d0945a8dfa418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e7d1d3e98c949cb832ce1a8bd7d1080",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9318905b99f64240bde9e7f5d567ef62"
          }
        },
        "ae0237a296cb45ec942502b707e47b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2cb48f311ed149528391662329830e08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6e3da4fe86e432e9284c2c94bc9876f"
          }
        },
        "6927c1a2ef9f48dfb90114f1f875fb11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_398eb8a209b843e89c6c211a24623117",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 2.54MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d50fe38b9abd4ca98182b5cae4bc2fb8"
          }
        },
        "5e7d1d3e98c949cb832ce1a8bd7d1080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9318905b99f64240bde9e7f5d567ef62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cb48f311ed149528391662329830e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6e3da4fe86e432e9284c2c94bc9876f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "398eb8a209b843e89c6c211a24623117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d50fe38b9abd4ca98182b5cae4bc2fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5164d52bf54d48099ae88cf4ed6ec70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d827dc7283bd4eccbebe0ad3247c831b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8454db51dfc241cfaca9cd7eaa3e14cc",
              "IPY_MODEL_49574e5a29354ad4abed2cefe26c6741",
              "IPY_MODEL_ea7f2ad302c140afa69b8a018e93e8b9"
            ]
          }
        },
        "d827dc7283bd4eccbebe0ad3247c831b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8454db51dfc241cfaca9cd7eaa3e14cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e180de5b1c04aafb4074c96f4315d89",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_629ce76dc9b146878098d5cb29885a45"
          }
        },
        "49574e5a29354ad4abed2cefe26c6741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d93c3971d37a4b72bdfd0d34f2270469",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c872351ce2f3433abcacd3c2106569d3"
          }
        },
        "ea7f2ad302c140afa69b8a018e93e8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a392577cd6774cbb846846e1ef0300be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 18.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6149185e39e4ca4acd9721732d66303"
          }
        },
        "4e180de5b1c04aafb4074c96f4315d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "629ce76dc9b146878098d5cb29885a45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d93c3971d37a4b72bdfd0d34f2270469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c872351ce2f3433abcacd3c2106569d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a392577cd6774cbb846846e1ef0300be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6149185e39e4ca4acd9721732d66303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VblewboMFPCH"
      },
      "source": [
        "model_name='google/electra-base-discriminator'\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7LTsnXNd86Y"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AD3_0qed-RH"
      },
      "source": [
        "#Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKNujlpgeFFW"
      },
      "source": [
        "The data that i'm gonna use is the Pandora data set, \n",
        "https://paperswithcode.com/dataset/pandora. PANDORA is the first large-scale dataset of Reddit comments labeled with different personality models (including the well-established Big 5 model and MBTI model) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETRABGuAP9bH",
        "outputId": "881dd694-dcc0-4156-9920-7a0414ce34a2"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AH2SVXmrFtA"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "811BKms-evtb"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E161kEVxezu1"
      },
      "source": [
        "The pandora dataset come in three different files\n",
        "\n",
        "1.   author_profiles.csv\n",
        "2.   all_comments_since_2015\n",
        "3.   subreddits_mbti.csv\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBzDGEHqfVp5"
      },
      "source": [
        "#The author_profiles.csv file: \n",
        "this file Contain more the 10K user profile where 9k are annotated with the MBTI personality test traits and 1k are annotated with the BIG5 traits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giBLTEhBfU42"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb0cezADiHkD"
      },
      "source": [
        "df=pd.read_csv(\"./drive/MyDrive/Data/author_profiles.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugXjQLIhiDJb",
        "outputId": "e965c3b7-6f7f-446d-c74e-59b8a76bd733"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['author', 'mbti', 'introverted', 'intuitive', 'thinking', 'perceiving',\n",
              "       'gender', 'age', 'enneagram', 'country', 'state', 'type',\n",
              "       'agreeableness', 'openness', 'conscientiousness', 'extraversion',\n",
              "       'neuroticism', 'is_description', 'is_percentile', 'is_score',\n",
              "       'contains_details', 'num_comments', 'en_comments',\n",
              "       'en_comments_percentage', 'region', 'continent', 'country_code',\n",
              "       'enneagram_type', 'enneagram_wing', 'is_native_english_country',\n",
              "       'predicted_test', 'test_name', 'test_scale', '16pers_ta',\n",
              "       'test_result_type', 'is_female', 'is_female_pred', 'is_female_proba'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JMyXyzJiNta"
      },
      "source": [
        "The author profile contains differrent features suh as the author id , its  gender its age, its region , its country and the values for the personality traits.\n",
        "\n",
        "We are interested only on the values for the MBTI and BIG5 personality traits:\n",
        "\n",
        "'agreeableness', 'openness', 'conscientiousness', 'extraversion',\n",
        "       'neuroticism',\"introverted\",\t\"intuitive\",\t\"thinking\",\t\"perceiving\"\n",
        "\n",
        "As in this work we aim to predict the personality of the user from its comments on the Reddit platform without taking into concideration its gender or age etc.. just from the text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlAmYq-fiLnc"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNe-HVb2iDJb"
      },
      "source": [
        "df_profile=df[[\"author\",'agreeableness', 'openness', 'conscientiousness', 'extraversion',\n",
        "       'neuroticism',\"introverted\",\t\"intuitive\",\t\"thinking\",\t\"perceiving\"]]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nfj6bQIiDJc",
        "outputId": "c345ca98-62be-46d6-a894-0bbdaaa48950"
      },
      "source": [
        "len(df_profile.author.unique())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10295"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "APPPRj-4jUvC",
        "outputId": "d1e64664-022b-4e42-9d72-ed03948c79aa"
      },
      "source": [
        "#Verify the number of profiles that are annotqted with the Bi5 traits\n",
        "df_profile[['agreeableness', 'openness', 'conscientiousness', 'extraversion','neuroticism']].dropna()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>agreeableness</th>\n",
              "      <th>openness</th>\n",
              "      <th>conscientiousness</th>\n",
              "      <th>extraversion</th>\n",
              "      <th>neuroticism</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>39.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>50.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>50.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>60.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10290</th>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10291</th>\n",
              "      <td>21.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10292</th>\n",
              "      <td>84.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10293</th>\n",
              "      <td>6.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>13.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1568 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       agreeableness  openness  conscientiousness  extraversion  neuroticism\n",
              "1                0.0      99.0               96.0          60.0          1.0\n",
              "6               39.0      92.0                1.0          18.0          4.0\n",
              "7               50.0      85.0               15.0          50.0         30.0\n",
              "8               50.0      85.0               50.0          85.0         50.0\n",
              "23              60.0      67.0               45.0          10.0         47.0\n",
              "...              ...       ...                ...           ...          ...\n",
              "10290            0.0      92.0               52.0           1.0         79.0\n",
              "10291           21.0      96.0               86.0          32.0          0.0\n",
              "10292           84.0      78.0               56.0           0.0          2.0\n",
              "10293            6.0      91.0               88.0          15.0          4.0\n",
              "10294           13.0      42.0               97.0           0.0          7.0\n",
              "\n",
              "[1568 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "obSHO9hJj_vE",
        "outputId": "1ed16fc6-8055-4c60-bf76-11f6e89ee706"
      },
      "source": [
        "#Verify the number of profiles that are annotated with the MBTI traits\n",
        "df_profile[[\"introverted\",\t\"intuitive\",\t\"thinking\",\t\"perceiving\"]].dropna()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>introverted</th>\n",
              "      <th>intuitive</th>\n",
              "      <th>thinking</th>\n",
              "      <th>perceiving</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10289</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10290</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10291</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10293</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9067 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       introverted  intuitive  thinking  perceiving\n",
              "0              1.0        1.0       1.0         1.0\n",
              "2              0.0        1.0       1.0         1.0\n",
              "3              0.0        1.0       1.0         0.0\n",
              "4              1.0        1.0       1.0         1.0\n",
              "5              0.0        1.0       1.0         1.0\n",
              "...            ...        ...       ...         ...\n",
              "10289          0.0        1.0       0.0         1.0\n",
              "10290          1.0        1.0       1.0         0.0\n",
              "10291          1.0        1.0       1.0         0.0\n",
              "10293          1.0        1.0       1.0         0.0\n",
              "10294          1.0        1.0       1.0         0.0\n",
              "\n",
              "[9067 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0lju6EeXkeEb",
        "outputId": "a514cbf6-8662-46f2-9362-778c0be3e086"
      },
      "source": [
        "#Verify the number of profiles that are annotated with both BIG5 and  MBTI traits\n",
        "df_profile[['agreeableness', 'openness', 'conscientiousness', 'extraversion',\n",
        "       'neuroticism',\"introverted\",\t\"intuitive\",\t\"thinking\",\t\"perceiving\"]].dropna()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>agreeableness</th>\n",
              "      <th>openness</th>\n",
              "      <th>conscientiousness</th>\n",
              "      <th>extraversion</th>\n",
              "      <th>neuroticism</th>\n",
              "      <th>introverted</th>\n",
              "      <th>intuitive</th>\n",
              "      <th>thinking</th>\n",
              "      <th>perceiving</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>50.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>60.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>10.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10289</th>\n",
              "      <td>3.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10290</th>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10291</th>\n",
              "      <td>21.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10293</th>\n",
              "      <td>6.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>13.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>377 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       agreeableness  openness  ...  thinking  perceiving\n",
              "7               50.0      85.0  ...       1.0         1.0\n",
              "23              60.0      67.0  ...       0.0         1.0\n",
              "58               0.0      37.0  ...       1.0         1.0\n",
              "138             10.0      80.0  ...       1.0         0.0\n",
              "169              1.0      50.0  ...       0.0         1.0\n",
              "...              ...       ...  ...       ...         ...\n",
              "10289            3.0      85.0  ...       0.0         1.0\n",
              "10290            0.0      92.0  ...       1.0         0.0\n",
              "10291           21.0      96.0  ...       1.0         0.0\n",
              "10293            6.0      91.0  ...       1.0         0.0\n",
              "10294           13.0      42.0  ...       1.0         0.0\n",
              "\n",
              "[377 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAtPmKDSjG9G"
      },
      "source": [
        "we can see that in this dataset we have exactlu 10295 unique profile where \n",
        "\n",
        "\n",
        "1.   1568 are annotated with the BIG5 traits\n",
        "2.   9067 are annotated with the MBTI traits\n",
        "3.   377  are annotated with both MBTI and BIG5 traits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT77gy_ekxmh"
      },
      "source": [
        "As in this work we aim to predict both the MBTI and BIG5 traits, we will focus only on the 377 profiles that are annotated with both of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "HW8z3qaEkm8z",
        "outputId": "e8f63d28-9ea2-4308-f422-c8eb6b35e956"
      },
      "source": [
        "df_profile=df_profile.dropna(subset=['introverted',\t'intuitive',\t'thinking',\t'perceiving','agreeableness',\t'openness',\t'conscientiousness',\t'extraversion',\t'neuroticism'])\n",
        "df_profile"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>agreeableness</th>\n",
              "      <th>openness</th>\n",
              "      <th>conscientiousness</th>\n",
              "      <th>extraversion</th>\n",
              "      <th>neuroticism</th>\n",
              "      <th>introverted</th>\n",
              "      <th>intuitive</th>\n",
              "      <th>thinking</th>\n",
              "      <th>perceiving</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-BlitzN9ne</td>\n",
              "      <td>50.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-dyad-</td>\n",
              "      <td>60.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>12345jk12345</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>ACE_C0ND0R</td>\n",
              "      <td>10.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>A_Bra_and_a_Ham</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10289</th>\n",
              "      <td>quakeroaks</td>\n",
              "      <td>3.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10290</th>\n",
              "      <td>rrgjl</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10291</th>\n",
              "      <td>seldomvanilla</td>\n",
              "      <td>21.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10293</th>\n",
              "      <td>turncloak471</td>\n",
              "      <td>6.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>yrelav_dnomyar</td>\n",
              "      <td>13.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>377 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                author  agreeableness  ...  thinking  perceiving\n",
              "7           -BlitzN9ne           50.0  ...       1.0         1.0\n",
              "23              -dyad-           60.0  ...       0.0         1.0\n",
              "58        12345jk12345            0.0  ...       1.0         1.0\n",
              "138         ACE_C0ND0R           10.0  ...       1.0         0.0\n",
              "169    A_Bra_and_a_Ham            1.0  ...       0.0         1.0\n",
              "...                ...            ...  ...       ...         ...\n",
              "10289       quakeroaks            3.0  ...       0.0         1.0\n",
              "10290            rrgjl            0.0  ...       1.0         0.0\n",
              "10291    seldomvanilla           21.0  ...       1.0         0.0\n",
              "10293     turncloak471            6.0  ...       1.0         0.0\n",
              "10294   yrelav_dnomyar           13.0  ...       1.0         0.0\n",
              "\n",
              "[377 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCw91pKElY7G"
      },
      "source": [
        "As we can see in the previous table , the MBTI trait values {'introverted',\t'intuitive',\t'thinking',\t'perceiving'} are binary values (they contain only 0 or 1 to define whether the profile belong to the category or not). However for the BIG5 traits, we can see that they are numerical values (for 0 to 100) which instead of indicating wether the profile belong to a category or not like the MBTI does, these values indicates to which degree a profile belong to a category. meaning that in the BIG5 traits a profile will belong to all the categories but with a degree of beloniging. Wheras in MBTI the values defines i f the user belong to the trait or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqSbXwwCmxRu"
      },
      "source": [
        "### Contribution\n",
        "From the table above we can see that we have two problems:\n",
        "\n",
        "1.   First we have a multi label classification task for the MBTI traits\n",
        "2.   First we have a multi label regression task for the BIG5 traits\n",
        "\n",
        "In order to solve thease two problems we are proposing a Multi-Head (classification,regression) network that given a text it will predict at the same time both the value of each MBTI an Big5 trait factor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PhLevVXntqt"
      },
      "source": [
        "Now that we filtred the profiles that we arw gonna use, we will combine them wiith all their comments that they said since 2015.\n",
        "\n",
        "To do that we need to call the all all_comments_since_2015.csv that comes with the Pendora package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA8eqlAD6gqq"
      },
      "source": [
        "df=pd.read_csv(\"./drive/MyDrive/Data/all_comments_since_2015.csv\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPs2RucZogaX",
        "outputId": "49c2e84f-0a01-408e-e138-8837b5dbe671"
      },
      "source": [
        "len(df)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17640062"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIvaJysYoMF7"
      },
      "source": [
        "#### all_comments_since_2015.csv\n",
        "\n",
        "This file contain all the comments from 2015 to 2020 for all the profiles in the Pnadora dataset. It contains more than 17M comment.\n",
        "However due to the fact not all profiles are annotated with both MBTI and BIG5 factors. We will keep only the comments that correspond to the filtred profiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWkejlzEppRB",
        "outputId": "f7f098c9-2084-4216-8b92-4931c613b14c"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['author', 'author_flair_text', 'body', 'downs', 'created_utc',\n",
              "       'subreddit_id', 'link_id', 'parent_id', 'score', 'controversiality',\n",
              "       'gilded', 'id', 'subreddit', 'ups', 'word_count',\n",
              "       'word_count_quoteless', 'lang'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mpludYGRqPlL",
        "outputId": "b2aeeb12-a5d8-426f-942e-dbb08424c925"
      },
      "source": [
        "df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>author_flair_text</th>\n",
              "      <th>body</th>\n",
              "      <th>downs</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>subreddit_id</th>\n",
              "      <th>link_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>score</th>\n",
              "      <th>controversiality</th>\n",
              "      <th>gilded</th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>ups</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_count_quoteless</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>ENTP</td>\n",
              "      <td>Those stats come from the test. [Echoing the c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.474429e+09</td>\n",
              "      <td>t5_2s90r</td>\n",
              "      <td>t3_53plrw</td>\n",
              "      <td>t3_53plrw</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>d7vkyrf</td>\n",
              "      <td>mbti</td>\n",
              "      <td>6.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>That's great to hear! I hope you know that, de...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.480139e+09</td>\n",
              "      <td>t5_2s90r</td>\n",
              "      <td>t3_5ep948</td>\n",
              "      <td>t1_dafz6ab</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dafzzrg</td>\n",
              "      <td>mbti</td>\n",
              "      <td>0.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>[ENTP-5 M 22]</td>\n",
              "      <td>I can totally agree on reticence! With respect...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.455096e+09</td>\n",
              "      <td>t5_2s90r</td>\n",
              "      <td>t3_44q2vf</td>\n",
              "      <td>t1_cztchk3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>czul5ag</td>\n",
              "      <td>mbti</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>&lt;U+1D07&gt;&lt;U+0274&gt;&lt;U+1D1B&gt;&lt;U+1D18&gt; - &lt;U+1D1B&gt;&lt;U+...</td>\n",
              "      <td>I took it several times. I'm typed as TYPE_MEN...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.462865e+09</td>\n",
              "      <td>t5_2s90r</td>\n",
              "      <td>t3_4ijf4l</td>\n",
              "      <td>t3_4ijf4l</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>d2zo611</td>\n",
              "      <td>mbti</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>&lt;U+1D07&gt;&lt;U+0274&gt;&lt;U+1D1B&gt;&lt;U+1D18&gt; - &lt;U+1D1B&gt;&lt;U+...</td>\n",
              "      <td>Gawd it's like we don't even need drugs to be ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.460656e+09</td>\n",
              "      <td>t5_2s90r</td>\n",
              "      <td>t3_4eptxr</td>\n",
              "      <td>t1_d22uh4r</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>d22uu81</td>\n",
              "      <td>mbti</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17640057</th>\n",
              "      <td>ilikehockeyandguitar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I kinda feel the same way about Animal Collect...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.527879e+09</td>\n",
              "      <td>t5_2zj24</td>\n",
              "      <td>t3_8nt3u5</td>\n",
              "      <td>t1_dzy8o1n</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dzyenpb</td>\n",
              "      <td>indieheads</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17640058</th>\n",
              "      <td>Burning_Lovers</td>\n",
              "      <td>:flag-ca: California</td>\n",
              "      <td>have you seen how delusional Republican voters...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.541518e+09</td>\n",
              "      <td>t5_2cneq</td>\n",
              "      <td>t3_9unf4i</td>\n",
              "      <td>t1_e95v5f3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>e95vz50</td>\n",
              "      <td>politics</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17640059</th>\n",
              "      <td>WinterCharm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Good stuff :D I love immunology.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.523051e+09</td>\n",
              "      <td>t5_2szyo</td>\n",
              "      <td>t3_8ab9lo</td>\n",
              "      <td>t1_dwxqjef</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dwxqo62</td>\n",
              "      <td>Showerthoughts</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17640060</th>\n",
              "      <td>MizzElissa</td>\n",
              "      <td>��</td>\n",
              "      <td>You're not my real mom</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.530637e+09</td>\n",
              "      <td>t5_2vegg</td>\n",
              "      <td>t3_8vsap7</td>\n",
              "      <td>t1_e1q4vxt</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>e1q73lg</td>\n",
              "      <td>me_irl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17640061</th>\n",
              "      <td>permanent_staff</td>\n",
              "      <td>♂ edited for spelling</td>\n",
              "      <td>Who are these people commenting on your life?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.534712e+09</td>\n",
              "      <td>t5_34cyw</td>\n",
              "      <td>t3_98n6xg</td>\n",
              "      <td>t3_98n6xg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>e4hbuxy</td>\n",
              "      <td>datingoverthirty</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17640062 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        author  ... lang\n",
              "0              MetricExpansion  ...   en\n",
              "1              MetricExpansion  ...   en\n",
              "2              MetricExpansion  ...   en\n",
              "3              MetricExpansion  ...   en\n",
              "4              MetricExpansion  ...   en\n",
              "...                        ...  ...  ...\n",
              "17640057  ilikehockeyandguitar  ...   en\n",
              "17640058        Burning_Lovers  ...   en\n",
              "17640059           WinterCharm  ...   en\n",
              "17640060            MizzElissa  ...   en\n",
              "17640061       permanent_staff  ...   en\n",
              "\n",
              "[17640062 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVIIZJmp5Um"
      },
      "source": [
        "The dataset contains diffrent features suche as the wor_count of the comment, the time of creating the comment, language, the content of the comment, the author id etc..\n",
        "In this work we focus only on the content of the comment, as we are trying to predict the personality from the content of the user comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ayhmykapslo"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec2aI5b-zCN6"
      },
      "source": [
        "#we zill keep only the \"author\",'body' and \"created_utc\"\n",
        "df_comments=df[[\"author\",'body',\"created_utc\"]]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMD6EJUUrDDn"
      },
      "source": [
        "an example of a one comment of a profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "Mi_nVhHwcXJe",
        "outputId": "09c6deca-9074-4259-ccd0-2298bfb5344b"
      },
      "source": [
        "\n",
        "df_comments[\"body\"][0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Those stats come from the test. [Echoing the comment I just made on a related question](https://www.reddit.com/r/mbti/comments/53q3qt/why_do_so_many_people_ask_to_be_typed_when_you/d7vf1im), it depends on what an MBTI type means to you.If it's the four letter code from the dichotomies, then those type frequencies are legitimate as are the other scientific results where test-derived MBTI types are studied, up to the quality of the scientific work, of course. But then we're not guaranteed to be talking about cognitive functions at all.If it's the set of cognitive functions you use with a certain priority, as many here prefer to talk about, then those statistics and any scientific results pertaining to MBTI types are just *completely and utterly irrelevant* to the discussion because you're just not talking about the same thing they are. This includes TYPE_MENTION being rare, TYPE_MENTION having the highest IQ, TYPE_MENTION making the most money, TYPE_MENTION being the most common type in women, etc.\""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BscT4rmbrVfF"
      },
      "source": [
        "#### Concatenate the filtered profiles with their comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eRBX6jx1hX4"
      },
      "source": [
        "alld_data=pd.merge(df_comments,df_profile, on='author')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHfwJrU_rppN",
        "outputId": "ca6b0f9b-e2a7-44dd-deec-8fcb00d941ac"
      },
      "source": [
        "len(alld_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1045374"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbPZQuOfruPD"
      },
      "source": [
        "by concatinating the filtred profiles with their comments we went down to 1M\n",
        "\n",
        "It is true that loosing rows of data is not preferable. However we needed to do that because the other rows refer to profiles that either have MBTI traits or BIG5 traits not both. Also 1M row of data is still a huge data quantity for a network to be trained on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzWxLHa8b978"
      },
      "source": [
        "alld_data.dropna(inplace=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn6I2bJM1705",
        "outputId": "848b6833-de95-4983-d99a-ebef549ae34a"
      },
      "source": [
        "alld_data.info()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1045374 entries, 0 to 1045373\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   author             1045374 non-null  object \n",
            " 1   body               1045374 non-null  object \n",
            " 2   created_utc        1045374 non-null  float64\n",
            " 3   agreeableness      1045374 non-null  float64\n",
            " 4   openness           1045374 non-null  float64\n",
            " 5   conscientiousness  1045374 non-null  float64\n",
            " 6   extraversion       1045374 non-null  float64\n",
            " 7   neuroticism        1045374 non-null  float64\n",
            " 8   introverted        1045374 non-null  float64\n",
            " 9   intuitive          1045374 non-null  float64\n",
            " 10  thinking           1045374 non-null  float64\n",
            " 11  perceiving         1045374 non-null  float64\n",
            "dtypes: float64(10), object(2)\n",
            "memory usage: 103.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74mIKFUGsz60"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzIksM-0s4MX"
      },
      "source": [
        "Now lets take a look on the final data that we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVcyvkPkNrYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "outputId": "21c47a5b-fbe0-4820-a4e8-534b45926e8b"
      },
      "source": [
        "alld_data"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>agreeableness</th>\n",
              "      <th>openness</th>\n",
              "      <th>conscientiousness</th>\n",
              "      <th>extraversion</th>\n",
              "      <th>neuroticism</th>\n",
              "      <th>introverted</th>\n",
              "      <th>intuitive</th>\n",
              "      <th>thinking</th>\n",
              "      <th>perceiving</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>Those stats come from the test. [Echoing the c...</td>\n",
              "      <td>1.474429e+09</td>\n",
              "      <td>30.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>That's great to hear! I hope you know that, de...</td>\n",
              "      <td>1.480139e+09</td>\n",
              "      <td>30.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>I can totally agree on reticence! With respect...</td>\n",
              "      <td>1.455096e+09</td>\n",
              "      <td>30.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>I took it several times. I'm typed as TYPE_MEN...</td>\n",
              "      <td>1.462865e+09</td>\n",
              "      <td>30.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MetricExpansion</td>\n",
              "      <td>Gawd it's like we don't even need drugs to be ...</td>\n",
              "      <td>1.460656e+09</td>\n",
              "      <td>30.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045369</th>\n",
              "      <td>Mkmcat</td>\n",
              "      <td>Actually, I double checked my MBTI and I am EN...</td>\n",
              "      <td>1.519730e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045370</th>\n",
              "      <td>Mkmcat</td>\n",
              "      <td>Yes, my ring fingers are on both hands longer ...</td>\n",
              "      <td>1.519128e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045371</th>\n",
              "      <td>NinjaMine</td>\n",
              "      <td>Summoner name: NinjaMineI'm level 4 Teemo tras...</td>\n",
              "      <td>1.496300e+09</td>\n",
              "      <td>50.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045372</th>\n",
              "      <td>NinjaMine</td>\n",
              "      <td>Openness - 77%Conscientiousness - 68%Extravers...</td>\n",
              "      <td>1.521167e+09</td>\n",
              "      <td>50.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045373</th>\n",
              "      <td>madazzie</td>\n",
              "      <td>ISFJOpenness - 60%Conscientiousness - 71%Extra...</td>\n",
              "      <td>1.513742e+09</td>\n",
              "      <td>45.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1045374 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  author  ... perceiving\n",
              "0        MetricExpansion  ...        1.0\n",
              "1        MetricExpansion  ...        1.0\n",
              "2        MetricExpansion  ...        1.0\n",
              "3        MetricExpansion  ...        1.0\n",
              "4        MetricExpansion  ...        1.0\n",
              "...                  ...  ...        ...\n",
              "1045369           Mkmcat  ...        0.0\n",
              "1045370           Mkmcat  ...        0.0\n",
              "1045371        NinjaMine  ...        0.0\n",
              "1045372        NinjaMine  ...        0.0\n",
              "1045373         madazzie  ...        0.0\n",
              "\n",
              "[1045374 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BirPdWPi6ND8"
      },
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbtelG_DthAI"
      },
      "source": [
        "Now that we filtred and created the data that we need, we will start now by creating the learning model architecture.\n",
        "\n",
        "To do that in a nutshell we will use the hugging face librarie to fune-tune a pretrained model so that it encodes the comments of the profile in a contextual way. Then using thease vector embeddings we will train a multi-task neural network to predict both MBTI and BIG5 values. All of this is done in an END-To-END network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGB_F5r7xY9g"
      },
      "source": [
        "We will start firs by importing all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGdQ-vgX6uEq",
        "outputId": "92d13231-79a3-484a-f929-2aaaa3728744"
      },
      "source": [
        "\n",
        " \n",
        "!pip install transformers\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 42.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDcFwtwgELKH",
        "outputId": "87c8316b-6386-456e-c70d-e2fe7283a3a5"
      },
      "source": [
        "!pip install audtorch"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting audtorch\n",
            "  Downloading audtorch-0.6.4-py3-none-any.whl (54 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 40 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from audtorch) (0.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from audtorch) (1.9.0+cu111)\n",
            "Collecting audiofile\n",
            "  Downloading audiofile-1.0.0-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from audtorch) (1.1.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from audtorch) (0.8.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from audtorch) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from audtorch) (1.19.5)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from audtorch) (0.8.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (0.22.2.post1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (0.51.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (21.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (2.1.9)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (1.0.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (1.5.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (0.10.3.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->audtorch) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->audtorch) (0.34.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.8.0->audtorch) (2.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->audtorch) (2.23.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->audtorch) (1.4.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy->audtorch) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.8.0->audtorch) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.8.0->audtorch) (2.20)\n",
            "Collecting audeer\n",
            "  Downloading audeer-1.16.0-py3-none-any.whl (14 kB)\n",
            "Collecting sox\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->audtorch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->audtorch) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.8.0->audtorch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.8.0->audtorch) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.8.0->audtorch) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.8.0->audtorch) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->audtorch) (3.7.4.3)\n",
            "Installing collected packages: sox, audeer, audiofile, audtorch\n",
            "Successfully installed audeer-1.16.0 audiofile-1.0.0 audtorch-0.6.4 sox-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W4UL8aK6uEq",
        "outputId": "0b3f1cd4-4289-4981-da13-0d1491f5bb42"
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 19 21:06:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQLj3h_y6uEq",
        "outputId": "ce15a71c-f586-4dfc-c340-3a46ed8bf472"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import audtorch\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss,MSELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, ElectraTokenizer, ElectraModel, ElectraConfig\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SoX could not be found!\n",
            "\n",
            "    If you do not have SoX, proceed here:\n",
            "     - - - http://sox.sourceforge.net/ - - -\n",
            "\n",
            "    If you do (or think that you should) have SoX, double-check your\n",
            "    path variables.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2EQWZctxwbP"
      },
      "source": [
        "Before start creating the model we need first to prepare our data so that thei'll bee appropriate to be consumed by our model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8btH6qBuyB0i"
      },
      "source": [
        "We need first to devide our data into training, test and validation sets.\n",
        "\n",
        "\n",
        "1.   The train data will be used as the main data to train the model\n",
        "2.   the validation data will be used also during the training phase but just to validate the performance of the model during the training phase.\n",
        "3.   The test data will be used as a holdout data that has not been seen by the model in order to truly evaluate the generalization of our model\n",
        "\n",
        "We will use 669K of dqtq rows to train the model, 167k as a validation data and 209k as test data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9-R5pg24G3b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train,test = train_test_split(alld_data, test_size=0.2,random_state =0)\n",
        "train,valid = train_test_split(train, test_size=0.2,random_state =0)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vINM0o4H40AN",
        "outputId": "88cfa2f6-4dfe-48e8-cc57-b0bdd6b926e4"
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "669039"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MXR-65y5CE9",
        "outputId": "3d44fcce-f415-4310-c5b1-b5e55a187683"
      },
      "source": [
        "len(test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "209075"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tU-P3we5umN"
      },
      "source": [
        "train=train[:int(len(train)/10)]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn2q6x5E0gTq"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSHU70IjO-_E"
      },
      "source": [
        "test=test[:int(len(test)/10)]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpRaMBU1O_PL"
      },
      "source": [
        "valid=valid[:int(len(valid)/10)]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5unzcFJPX7O",
        "outputId": "ffcab707-7597-4dba-8ee1-a44122c5d8f2"
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66903"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl8ygUNDPX7O",
        "outputId": "dc82e978-be13-4d3e-a794-1fbb3b5b9531"
      },
      "source": [
        "len(test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20907"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHdOWJ2I0pan"
      },
      "source": [
        "Now that we have the data for the different tasks that we need. we will use a pretrained Electra transformer model to encode the context of the comments for each row. to do that we need first to instanciate the Electra pretrained model fron the Hugging face library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpEsq9w31o8R"
      },
      "source": [
        "#Define the Electra model name from the hugging face library\n",
        "model_name='google/electra-small-discriminator'\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp1IMuIq2fFE"
      },
      "source": [
        "Instanciate the tokenizer of the pre_trqined model\n",
        "\n",
        "The tokenizer will transform th textual data into different vectors, where each vector present differnt isights such as the vector of positions of eqch word in the sentence, The vector of token repesentensqtion for eqch word in the sentence and the vector of masking values for each word in the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ee50d3eb44984fd68a04dd22d33a765c",
            "e86ae12ffb4948cb8a1af49c38038b47",
            "4a30911b6b054d3ea197ccfcfb8e666f",
            "1f13b86301774ade8fb257047e1800a8",
            "6a50263fbd574ea2af76896a50bbebd2",
            "8c3813e8a1d24f24acc1af06e4fff0c7",
            "be48b471d5504e6daf03b6f2f1ab100b",
            "d71aad9266fc4425b75399a9cbbe46f9",
            "c9fd848ed901450b85c96b8659c08797",
            "b68c7b0b6eae4753b864ac1a49da33df",
            "f6a23eb688764a18b130408578b10791",
            "684ecd4caaed4430a69b0924b37f3ca4",
            "4a65541bc2bd4b6fa6c8f343edaf3648",
            "53b411a51b644c619e37132aea1200d5",
            "f645c125488d425ab0632bd56f8d8b19",
            "b67724c74eea46b0bd2194b75e59edbf",
            "ff2a67fdfb77477696b6050d1cb2683b",
            "b68ded0ff9504f6f97e619f29e5fe965",
            "f052a7a7d2264f50bc4b04db140ca1fd",
            "3225afb48ca74e34a6a14c4b51bdce77",
            "7a607147dd3e4bb1845f233778414d59",
            "f1625ea769b847c684a2772ba589289b",
            "8c19302d49a34749b9d7d010468a3720",
            "0459f1a84bb34665918057e9ebe8ad5b",
            "376a4576f274439fa80d0945a8dfa418",
            "ae0237a296cb45ec942502b707e47b71",
            "6927c1a2ef9f48dfb90114f1f875fb11",
            "5e7d1d3e98c949cb832ce1a8bd7d1080",
            "9318905b99f64240bde9e7f5d567ef62",
            "2cb48f311ed149528391662329830e08",
            "e6e3da4fe86e432e9284c2c94bc9876f",
            "398eb8a209b843e89c6c211a24623117",
            "d50fe38b9abd4ca98182b5cae4bc2fb8",
            "5164d52bf54d48099ae88cf4ed6ec70b",
            "d827dc7283bd4eccbebe0ad3247c831b",
            "8454db51dfc241cfaca9cd7eaa3e14cc",
            "49574e5a29354ad4abed2cefe26c6741",
            "ea7f2ad302c140afa69b8a018e93e8b9",
            "4e180de5b1c04aafb4074c96f4315d89",
            "629ce76dc9b146878098d5cb29885a45",
            "d93c3971d37a4b72bdfd0d34f2270469",
            "c872351ce2f3433abcacd3c2106569d3",
            "a392577cd6774cbb846846e1ef0300be",
            "d6149185e39e4ca4acd9721732d66303"
          ]
        },
        "id": "kEoxOnfBRBtW",
        "outputId": "97da3751-85cf-4754-cacd-09330e771895"
      },
      "source": [
        "#\n",
        "tokenizer = ElectraTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "train_data= train[\"body\"].values\n",
        "test_data = test[\"body\"].values\n",
        "valid_data = valid[\"body\"].values\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee50d3eb44984fd68a04dd22d33a765c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "684ecd4caaed4430a69b0924b37f3ca4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c19302d49a34749b9d7d010468a3720",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5164d52bf54d48099ae88cf4ed6ec70b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_fFd3Ub229m"
      },
      "source": [
        "In order to gather the ensights that we need we define a helper function \n",
        "Input_Tokenization that will instanciate the pre-trained Electra tokenizer and tokenize each row sentence. We will apply this function for all the training, test, and validation data so that we create mebedding vectors for each row on them. Thoes embedded vectors will be passed then to the Prediction network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTpWTB5kShO-"
      },
      "source": [
        "def Input_Tokenization(liste, tokenizer):\n",
        "    \n",
        "    outputs = tokenizer.batch_encode_plus(liste,padding=True,truncation=True,return_tensors='pt',return_attention_mask=True)    \n",
        "\n",
        "    return (outputs.input_ids,outputs.attention_mask)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fEQLMpiTTbf"
      },
      "source": [
        "train_input_ids,train_attention_masks=Input_Tokenization(train_data, tokenizer)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8k5gaG5UGRg"
      },
      "source": [
        "test_input_ids,test_attention_masks=Input_Tokenization(test_data, tokenizer)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkUP6ReIEohL"
      },
      "source": [
        "valid_input_ids,valid_attention_masks=Input_Tokenization(valid_data, tokenizer)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgX_imTZ31Ia"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLQqpRfk32i7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0aH8Efg32r4"
      },
      "source": [
        "If we take a closer look to the train_input_ids wich represent the encoding of each row in the training data we can see that the row of texts were transformed into rows of vector of numbers, where each vector of numbers represent a textual comment and each number in the vector represent a word identificator in the comment. The numbers are token representation were each number refer to a word in the pre_trained Electra vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-thJiQYAiKW",
        "outputId": "982965e8-5d97-4b05-8836-7646978c9ebc"
      },
      "source": [
        "train_input_ids"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 2009, 1005,  ...,    0,    0,    0],\n",
              "        [ 101, 2327, 9874,  ...,    0,    0,    0],\n",
              "        [ 101, 2619, 2425,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101, 1045, 2245,  ...,    0,    0,    0],\n",
              "        [ 101, 7110, 1005,  ...,    0,    0,    0],\n",
              "        [ 101, 2023, 2003,  ...,    0,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54pH1I8a4vQ2",
        "outputId": "2a6a1b6e-e46a-487b-b6ce-99b386351a08"
      },
      "source": [
        "train_input_ids[0]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  2009,  1005,  1055,  2069,  2026,  6772,  2008,  2045,  2003,\n",
              "         2070,  4066,  1997,  5415,  2344,  1998,  3800,  2008,  7906,  2033,\n",
              "         2013,  2108,  1037, 13076,  9152, 19466,  2923,  1012,  2026,  2828,\n",
              "         1035,  5254,  2190,  2767,  1998,  1045,  2024,  1031,  2183,  2004,\n",
              "         1996,  3124,  2006,  1996,  2157,  2005, 14414,  1033,  1006, 16770,\n",
              "         1024,  1013,  1013, 27263,  2015,  1012,  2006,  5332, 17644,  1012,\n",
              "         4012,  1013, 12991, 13874,  1011,  2498,  1011,  1999,  1011,  2166,\n",
              "         1011, 14085,  7747,  1011,  9152, 19466,  2964,  1011,  4507,  1011,\n",
              "        19734, 12190,  1011,  4090,  2683, 28311, 17134,  1012,  1052,  3070,\n",
              "         1007,  1010,  2138,  2057,  2119,  6709,  2007,  2009,  2061,  2172,\n",
              "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kkHFTBD41v7"
      },
      "source": [
        "Now that we transformed our data into a numerical values 'vectors of numbers' instead of the original textual values we will now transform them into a convininet form to be consumed by the Pytorch platform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo9DL-Lx5IBV"
      },
      "source": [
        "To do that we need first to define the names of label features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDL-kczoiG_i"
      },
      "source": [
        "label_cols = ['agreeableness', 'openness',\n",
        "       'conscientiousness', 'extraversion', 'neuroticism', 'introverted',\n",
        "       'intuitive', 'thinking', 'perceiving']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZbps7i75Uvb"
      },
      "source": [
        "Like we said, our model is a multi task prediction model. so we have classification labels and regression labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hEdKKmKDqta"
      },
      "source": [
        "#Classification labels\n",
        "clas_label_cols=[ 'introverted',\n",
        "       'intuitive', 'thinking', 'perceiving']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPnf22NfDq0x"
      },
      "source": [
        "#Regression labels\n",
        "reg_label_cols=['agreeableness', 'openness',\n",
        "       'conscientiousness', 'extraversion', 'neuroticism']"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5YE14y25phW"
      },
      "source": [
        "During the training phase we will need for both the training set and the validation set. Meaning that we will need for both the training and validation vector representations as well as the the classification and regression labels.\n",
        "\n",
        "For each row we need to  have the tokenization(ids and mask) of that row and ist MBTI(classification labels) and BIG5(regression labels) values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL9ocsItUQh_"
      },
      "source": [
        "\n",
        "\n",
        "X_train,train_masks,Y_train_r,Y_train_c = (train_input_ids,train_attention_masks,torch.tensor(train[reg_label_cols].values.tolist(),dtype=torch.float32),torch.tensor(train[clas_label_cols].values.tolist(),dtype=torch.float32))\n",
        "X_valid,valid_masks,Y_valid_r,Y_valid_c = (valid_input_ids,valid_attention_masks,torch.tensor(valid[reg_label_cols].values.tolist(),dtype=torch.float32),torch.tensor(valid[clas_label_cols].values.tolist(),dtype=torch.float32))\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi_a-SWY6eCl"
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsQVhxY96eTc"
      },
      "source": [
        "if we take a closer look to the first row information in the training data we can find :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo7FADsC6o_M",
        "outputId": "bd2334e8-b65c-4465-f4ca-da0d9a40add3"
      },
      "source": [
        "X_train[0]# the comment representation 'tokenization' of the first row\n",
        "#We can see a lot of 0 values. This is because the vector size of the pre-trqined Electra model id 256. and the nuber of words in the first comment are less than 256 \n",
        "#So the 0 values are added as a padding values to make all the vectors have the same size"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  2009,  1005,  1055,  2069,  2026,  6772,  2008,  2045,  2003,\n",
              "         2070,  4066,  1997,  5415,  2344,  1998,  3800,  2008,  7906,  2033,\n",
              "         2013,  2108,  1037, 13076,  9152, 19466,  2923,  1012,  2026,  2828,\n",
              "         1035,  5254,  2190,  2767,  1998,  1045,  2024,  1031,  2183,  2004,\n",
              "         1996,  3124,  2006,  1996,  2157,  2005, 14414,  1033,  1006, 16770,\n",
              "         1024,  1013,  1013, 27263,  2015,  1012,  2006,  5332, 17644,  1012,\n",
              "         4012,  1013, 12991, 13874,  1011,  2498,  1011,  1999,  1011,  2166,\n",
              "         1011, 14085,  7747,  1011,  9152, 19466,  2964,  1011,  4507,  1011,\n",
              "        19734, 12190,  1011,  4090,  2683, 28311, 17134,  1012,  1052,  3070,\n",
              "         1007,  1010,  2138,  2057,  2119,  6709,  2007,  2009,  2061,  2172,\n",
              "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEE4aaix7QK3",
        "outputId": "4d83c1e6-48b1-4379-e2c0-f2e47550b3cb"
      },
      "source": [
        "train_masks[0]# The mask represent binary values 0 or 1\n",
        "#1 means that the nodel will take into concideration the word in that position while 0 means that the model\n",
        "#will not take into concideration that word.\n",
        "#This is logic: as we can see all the 0 are puted in the position of the padding values in the above 'x_train[0]' comments.\n",
        "#which mean that the model will not concentrate on the padding values. It will concentrate only on the comment words values"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPhFin4A8CSc",
        "outputId": "f6e666c6-5406-4a52-a314-3c3f1d5c6dc8"
      },
      "source": [
        "Y_train_c[0]\n",
        "# The classification labels 'MBTI labels' for the first comment are "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XbTWIjk8QqQ",
        "outputId": "8f1dd9fd-a9e3-48e2-edb7-9115ea895394"
      },
      "source": [
        "Y_train_r[0]\n",
        "# The regression labels 'Big5 labels' for the first comment are "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([83., 80., 46., 37., 14.])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiO2feXC8X4I"
      },
      "source": [
        "Now that we know how our data looks like and the meaning of each data representation we will transform the data in a Pytorch format usign the data loader function to make them in chunks in order to trqin our model in a batch way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAJmRw-QVDdH"
      },
      "source": [
        "batch_size = 15\n",
        "\n",
        "\n",
        "train_data = TensorDataset(X_train, train_masks, Y_train_r,Y_train_c)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data,\\\n",
        "                              sampler=train_sampler,\\\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(X_valid, valid_masks, Y_valid_r,Y_valid_c)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data,\\\n",
        "                                   sampler=validation_sampler,\\\n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQGjBegaAWx0"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhbLeahSAW2s"
      },
      "source": [
        "from   torch.nn import BCELoss"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82UbrpRp81BQ"
      },
      "source": [
        "Now that the data is ready we will create the END-2-END neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31RIu85cVNx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "f94c7c27-97a0-4add-8bc9-14236bc8e5eb"
      },
      "source": [
        "'''class ElectraSharedWeights_Multi_Task(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, r_num_labels=2,c_num_labels=2):\n",
        "    super(ElectraForMultiLabelSequenceClassification, self).__init__()\n",
        "    self.c_num_labels = c_num_labels#The number of the classification labels whiche are 4 labels to use them as the final size for  the final linear layer\n",
        "    self.r_num_labels = r_num_labels#The number of the regression labels whiche are 5 labelsto use them as the final size for  the final linear layer\n",
        "    self.electra = ElectraModel.from_pretrained(model_name)#Instanciate  the pretrained model\n",
        "    self.layer1 = torch.nn.Linear(256, 150)# add The first linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.layer2  = torch.nn.Linear(150, 100)# add the second linear layer on top of the first one\n",
        "    self.layer3  = torch.nn.Linear(100, 50)# add the third linear layer on top of the second one\n",
        "    self.normilizer1  = torch.nn.BatchNorm1d(256)# add the normalizer to the electra values\n",
        "    self.normilizer2  = torch.nn.BatchNorm1d(100)# add the  normilizer layer onto the second layer values\n",
        "\n",
        "    #All the previous layers will be shared by the last separate two layers (classifier layer and regressor layer)\n",
        "\n",
        "    self.classifier = torch.nn.Linear(50, c_num_labels)# add the final linear layer for classification on top of the third layer   \n",
        "    self.regressor = torch.nn.Linear(50, r_num_labels)# add the final linear layer for regression on top of the third layer \n",
        "    self.drop=torch.nn.Dropout(p=0.4)# Define a dropout layer to overpass the overfitting during the training phase\n",
        "    self.leaky=torch.nn.LeakyReLU()# Use the Leaky Relu activation function as the ;ain activation function for the shared layers\n",
        "\n",
        "\n",
        "\n",
        "    #In order to train our models the weights need to be initialized, because if they were at 0, then the model will not be optimized so we need to\n",
        "    # inilize them. The most popular way to inisialize the weights is to use the Xavier initializer\n",
        "    torch.nn.init.xavier_normal_(self.layer1.weight) #initialise the weight of the first linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer2.weight) #initialise the weight of the second linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer3.weight) #initialise the weight of the third linear layer\n",
        "    torch.nn.init.xavier_normal_(self.classifier.weight) #initialise the weight of the classification layer\n",
        "    torch.nn.init.xavier_normal_(self.regressor.weight) #initialise the weight of th regression layer\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels_r=None,labels_c=None):\n",
        "    #Now that we defined the architecture and initialized the weights we need to define the forward function\n",
        "    #and how each defined variable will be used in the architecture\n",
        "\n",
        "    # last hidden layer\n",
        "    #for ech row we will use the ELECTRa model to create an embedding vector given the tokenized input\n",
        "    contextual_embedding = self.electra(input_ids=input_ids,\\\n",
        "                                   attention_mask=attention_mask,\\\n",
        "                                   token_type_ids=token_type_ids)\n",
        "\n",
        "    # pool the outputs into a mean vector\n",
        "    contextual_embedding = self.pool_hidden_state(contextual_embedding)\n",
        "    cl1 = self.leaky(self.layer1(contextual_embedding))\n",
        "    cl1=self.drop(cl1)\n",
        "    cl2 = self.leaky(self.layer2(cl1))\n",
        "    cl3 = self.leaky(self.layer3(cl2))\n",
        "    cl3=self.drop(cl3)\n",
        "    clogits = torch.sigmoid(self.classifier(cl3))\n",
        "\n",
        "    rl1 = self.leaky(self.layer1(mean_last_hidden_state))\n",
        "    rl1=self.drop(rl1)\n",
        "    rl2 = self.leaky(self.layer2(rl1))\n",
        "    rl3 = self.leaky(self.layer3(rl2))\n",
        "    rl3=self.drop(rl3)\n",
        "    rlogits = self.regressor(rl3)\n",
        "        \n",
        "    if ((labels_c is not None) and(labels_r is not None)):\n",
        "      closs_fct =BCEWithLogitsLoss()\n",
        "      rloss_fct = MSELoss()\n",
        "      #rloss_fct = audtorch.metrics.functional.pearsonr\n",
        "\n",
        "      closs = closs_fct(clogits.view(-1, self.c_num_labels),\\\n",
        "                      labels_c.view(-1, self.c_num_labels))\n",
        "      rloss=rloss_fct(rlogits.view(-1, self.r_num_labels),\\\n",
        "                      labels_r.view(-1, self.r_num_labels))\n",
        "\n",
        "      loss=(rloss+closs)/2\n",
        "      return loss\n",
        "    else:\n",
        "      return clogits,rlogits\n",
        "\n",
        "\n",
        "  def pool_hidden_state(self, last_hidden_state):\n",
        "    \"\"\"\n",
        "    Pool the output vectors into a single mean vector \n",
        "    \"\"\"\n",
        "    last_hidden_state = last_hidden_state[0]\n",
        "    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
        "    return mean_last_hidden_state\n",
        "    \n",
        "  \n",
        "\n",
        "# len(Y_train[0]) = 6\n",
        "'''"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'class ElectraSharedWeights_Multi_Task(torch.nn.Module):\\n  \\n  def __init__(self, r_num_labels=2,c_num_labels=2):\\n    super(ElectraForMultiLabelSequenceClassification, self).__init__()\\n    self.c_num_labels = c_num_labels#The number of the classification labels whiche are 4 labels to use them as the final size for  the final linear layer\\n    self.r_num_labels = r_num_labels#The number of the regression labels whiche are 5 labelsto use them as the final size for  the final linear layer\\n    self.electra = ElectraModel.from_pretrained(model_name)#Instanciate  the pretrained model\\n    self.layer1 = torch.nn.Linear(256, 150)# add The first linear layer on top of the encoding  discriminator layers of Electra \\n    self.layer2  = torch.nn.Linear(150, 100)# add the second linear layer on top of the first one\\n    self.layer3  = torch.nn.Linear(100, 50)# add the third linear layer on top of the second one\\n    self.normilizer1  = torch.nn.BatchNorm1d(256)# add the normalizer to the electra values\\n    self.normilizer2  = torch.nn.BatchNorm1d(100)# add the  normilizer layer onto the second layer values\\n\\n    #All the previous layers will be shared by the last separate two layers (classifier layer and regressor layer)\\n\\n    self.classifier = torch.nn.Linear(50, c_num_labels)# add the final linear layer for classification on top of the third layer   \\n    self.regressor = torch.nn.Linear(50, r_num_labels)# add the final linear layer for regression on top of the third layer \\n    self.drop=torch.nn.Dropout(p=0.4)# Define a dropout layer to overpass the overfitting during the training phase\\n    self.leaky=torch.nn.LeakyReLU()# Use the Leaky Relu activation function as the ;ain activation function for the shared layers\\n\\n\\n\\n    #In order to train our models the weights need to be initialized, because if they were at 0, then the model will not be optimized so we need to\\n    # inilize them. The most popular way to inisialize the weights is to use the Xavier initializer\\n    torch.nn.init.xavier_normal_(self.layer1.weight) #initialise the weight of the first linear layer\\n    torch.nn.init.xavier_normal_(self.layer2.weight) #initialise the weight of the second linear layer\\n    torch.nn.init.xavier_normal_(self.layer3.weight) #initialise the weight of the third linear layer\\n    torch.nn.init.xavier_normal_(self.classifier.weight) #initialise the weight of the classification layer\\n    torch.nn.init.xavier_normal_(self.regressor.weight) #initialise the weight of th regression layer\\n\\n  def forward(self, input_ids, token_type_ids=None,              attention_mask=None, labels_r=None,labels_c=None):\\n    #Now that we defined the architecture and initialized the weights we need to define the forward function\\n    #and how each defined variable will be used in the architecture\\n\\n    # last hidden layer\\n    #for ech row we will use the ELECTRa model to create an embedding vector given the tokenized input\\n    contextual_embedding = self.electra(input_ids=input_ids,                                   attention_mask=attention_mask,                                   token_type_ids=token_type_ids)\\n\\n    # pool the outputs into a mean vector\\n    contextual_embedding = self.pool_hidden_state(contextual_embedding)\\n    cl1 = self.leaky(self.layer1(contextual_embedding))\\n    cl1=self.drop(cl1)\\n    cl2 = self.leaky(self.layer2(cl1))\\n    cl3 = self.leaky(self.layer3(cl2))\\n    cl3=self.drop(cl3)\\n    clogits = torch.sigmoid(self.classifier(cl3))\\n\\n    rl1 = self.leaky(self.layer1(mean_last_hidden_state))\\n    rl1=self.drop(rl1)\\n    rl2 = self.leaky(self.layer2(rl1))\\n    rl3 = self.leaky(self.layer3(rl2))\\n    rl3=self.drop(rl3)\\n    rlogits = self.regressor(rl3)\\n        \\n    if ((labels_c is not None) and(labels_r is not None)):\\n      closs_fct =BCEWithLogitsLoss()\\n      rloss_fct = MSELoss()\\n      #rloss_fct = audtorch.metrics.functional.pearsonr\\n\\n      closs = closs_fct(clogits.view(-1, self.c_num_labels),                      labels_c.view(-1, self.c_num_labels))\\n      rloss=rloss_fct(rlogits.view(-1, self.r_num_labels),                      labels_r.view(-1, self.r_num_labels))\\n\\n      loss=(rloss+closs)/2\\n      return loss\\n    else:\\n      return clogits,rlogits\\n\\n\\n  def pool_hidden_state(self, last_hidden_state):\\n    \"\"\"\\n    Pool the output vectors into a single mean vector \\n    \"\"\"\\n    last_hidden_state = last_hidden_state[0]\\n    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\\n    return mean_last_hidden_state\\n    \\n  \\n\\n# len(Y_train[0]) = 6\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29feqtmPMk5k"
      },
      "source": [
        "class ElectraSharedWeights_Multi_Task(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, r_num_labels=2,c_num_labels=2):\n",
        "    super(ElectraSharedWeights_Multi_Task, self).__init__()\n",
        "    self.c_num_labels = c_num_labels#The number of the classification labels whiche are 4 labels to use them as the final size for  the final linear layer\n",
        "    self.r_num_labels = r_num_labels#The number of the regression labels whiche are 5 labelsto use them as the final size for  the final linear layer\n",
        "    self.electra = ElectraModel.from_pretrained(model_name)#Instanciate  the pretrained model\n",
        "    self.layer1 = torch.nn.Linear(256, 150)# add The first linear layer on top of the encoding  discriminator layers of Electra \n",
        "    self.layer2  = torch.nn.Linear(150, 100)# add the second linear layer on top of the first one\n",
        "    self.layer3  = torch.nn.Linear(100, 50)# add the third linear layer on top of the second one\n",
        "    #self.normilizer1  = torch.nn.BatchNorm1d(256)# add the normalizer to the electra values\n",
        "    #self.normilizer2  = torch.nn.BatchNorm1d(100)# add the  normilizer layer onto the second layer values\n",
        "    #All the previous layers will be shared by the last separate two layers (classifier layer and regressor layer)\n",
        "\n",
        "    self.classifier = torch.nn.Linear(50, c_num_labels)# add the final linear layer for classification on top of the third layer   \n",
        "    self.regressor = torch.nn.Linear(50, r_num_labels)# add the final linear layer for regression on top of the third layer \n",
        "    self.drop=torch.nn.Dropout(p=0.4)# Define a dropout layer to overpass the overfitting during the training phase\n",
        "    self.leaky=torch.nn.LeakyReLU()# Use the Leaky Relu activation function as the ;ain activation function for the shared layers\n",
        "\n",
        "\n",
        "\n",
        "    #In order to train our models the weights need to be initialized, because if they were at 0, then the model will not be optimized so we need to\n",
        "    # inilize them. The most popular way to inisialize the weights is to use the Xavier initializer\n",
        "    torch.nn.init.xavier_normal_(self.layer1.weight) #initialise the weight of the first linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer2.weight) #initialise the weight of the second linear layer\n",
        "    torch.nn.init.xavier_normal_(self.layer3.weight) #initialise the weight of the third linear layer\n",
        "    torch.nn.init.xavier_normal_(self.classifier.weight) #initialise the weight of the classification layer\n",
        "    torch.nn.init.xavier_normal_(self.regressor.weight) #initialise the weight of th regression layer\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels_r=None,labels_c=None):\n",
        "    #Now that we defined the architecture and initialized the weights we need to define the forward function\n",
        "    #and how each defined variable will be used in the architecture\n",
        "\n",
        "    # last hidden layer\n",
        "    #for ech row we will use the ELECTRa model to create an embedding vector given the tokenized input\n",
        "    Electra_hidding_state = self.electra(input_ids=input_ids,\\\n",
        "                                   attention_mask=attention_mask,\\\n",
        "                                   token_type_ids=token_type_ids)\n",
        "    contextual_embedding = Electra_hidding_state[0]\n",
        "    contextual_embedding = torch.mean(contextual_embedding, 1)\n",
        "    #contextual_embedding=self.normilizer1(contextual_embedding)\n",
        "    # pool the outputs into a mean vector\n",
        "    cl1 = self.leaky(self.layer1(contextual_embedding))\n",
        "    cl1=self.drop(cl1)\n",
        "    cl2 = self.leaky(self.layer2(cl1))\n",
        "    #cl2 = self.normilizer2(cl2)\n",
        "    cl3 = self.leaky(self.layer3(cl2))\n",
        "    cl3=self.drop(cl3)\n",
        "\n",
        "    #All the previous weights will be shared by both last layers (classifier and regresor) \n",
        "    clogits = self.classifier(cl3)# The classification results(MBTI Labels) given the shared weights\n",
        "\n",
        "    rlogits = self.regressor(cl3)# The regression results(BIG5 labels) given the shared weights\n",
        "\n",
        "\n",
        "    # Due to the fact that we have a multi-task learning model then we will have two different losses\n",
        "    # one to compute the classification loss and the other is to compute the regression loss\n",
        "    # We will use the BCE version for the classification loss and the MSE for the regression loss\n",
        "        \n",
        "    closs_fct =BCEWithLogitsLoss()# Classification loss\n",
        "    rloss_fct = MSELoss()# Regression loss\n",
        "\n",
        "    if ((labels_r is not None) and (labels_c is not None)):\n",
        "\n",
        "  \n",
        "      closs = closs_fct(clogits.view(-1, self.c_num_labels),\\\n",
        "                        labels_c.view(-1, self.c_num_labels))\n",
        "      rloss=rloss_fct(rlogits.view(-1, self.r_num_labels),\\\n",
        "                        labels_r.view(-1, self.r_num_labels))\n",
        "      #Because a model need to have one loss function to be trained on and be cause we need to minimise both regression and classification loss\n",
        "      #we create a combination of the regression loss and the classification loss by summing them and deviding by 2\n",
        "      #By combining both losses  into a one loss we will force the model to minimize the combination loss wich will lead to the minimization of the \n",
        "      #regression and the classification loss (minimizing their sum will lead to minimizing their original values)\n",
        "      loss=(rloss+closs)/2\n",
        "      return loss\n",
        "    else:\n",
        "      return clogits,rlogits\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESt2aHOLDUls"
      },
      "source": [
        "Noow that we created the architecture of our model we will instanciate it, make it capable of runing in paralell on defining it to be running on GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irZSxHu5Aknc",
        "outputId": "f71b2c39-0c30-409c-c797-6e7707bb65cc"
      },
      "source": [
        "model = ElectraSharedWeights_Multi_Task(c_num_labels=len(Y_train_c[0]),r_num_labels=len(Y_train_r[0]))\n",
        "model = torch.nn.DataParallel(model)\n",
        "model.cuda()\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): ElectraSharedWeights_Multi_Task(\n",
              "    (electra): ElectraModel(\n",
              "      (embeddings): ElectraEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 128)\n",
              "        (token_type_embeddings): Embedding(2, 128)\n",
              "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
              "      (encoder): ElectraEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): ElectraLayer(\n",
              "            (attention): ElectraAttention(\n",
              "              (self): ElectraSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): ElectraSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): ElectraIntermediate(\n",
              "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): ElectraOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer1): Linear(in_features=256, out_features=150, bias=True)\n",
              "    (layer2): Linear(in_features=150, out_features=100, bias=True)\n",
              "    (layer3): Linear(in_features=100, out_features=50, bias=True)\n",
              "    (classifier): Linear(in_features=50, out_features=4, bias=True)\n",
              "    (regressor): Linear(in_features=50, out_features=5, bias=True)\n",
              "    (drop): Dropout(p=0.4, inplace=False)\n",
              "    (leaky): LeakyReLU(negative_slope=0.01)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HaDt9NuNxBM",
        "outputId": "cc29f32d-75a5-4b8f-92f9-203c1f4fb1a1"
      },
      "source": [
        "!pip install hiddenlayer "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hiddenlayer\n",
            "  Downloading hiddenlayer-0.3-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwqLRobPNp9p"
      },
      "source": [
        "\n",
        "import torchvision.models\n",
        "import hiddenlayer as hl"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t9MbKOODoFv"
      },
      "source": [
        "We also need to define the Optimizer that we will use during the learning process for the gradient propagation. We will use the popular Adam optimizer with a 0.01 weight decay and a 2e-5 learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK-IgfCyWhOI"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01, correct_bias=False)\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJYPP4lMEN_q"
      },
      "source": [
        "Now we will define the training function for our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ridbti5JW8RA"
      },
      "source": [
        "def train(model, num_epochs,\\\n",
        "          optimizer,\\\n",
        "          train_dataloader, valid_dataloader,\\\n",
        "          model_save_path,\\\n",
        "          train_loss_set=[], valid_loss_set = [],\\\n",
        "          lowest_eval_loss=None, start_epoch=0,\\\n",
        "          device=\"cpu\"\n",
        "          ):\n",
        "  \"\"\"\n",
        "  Train the model and save the model with the lowest validation loss\n",
        "  \"\"\"\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  for i in trange(num_epochs, desc=\"Epoch\"):\n",
        "    \n",
        "    actual_epoch = start_epoch + i\n",
        "\n",
        "    \n",
        "\n",
        "    model.train()\n",
        "\n",
        "    tr_loss = 0\n",
        "    num_train_samples = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels_r,b_labels_c = batch\n",
        "      # Clear out the gradients (by default they accumulate)\n",
        "      optimizer.zero_grad()\n",
        "      # Forward pass\n",
        "      loss = model(b_input_ids, attention_mask=b_input_mask, labels_r=b_labels_r,labels_c=b_labels_c)\n",
        "      # store train loss\n",
        "      tr_loss += loss.item()\n",
        "      num_train_samples += b_labels_c.size(0)\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      # Update parameters and take a step using the computed gradient\n",
        "      optimizer.step()\n",
        "      #scheduler.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    epoch_train_loss = tr_loss/num_train_samples\n",
        "    train_loss_set.append(epoch_train_loss)\n",
        "\n",
        "    print(\"Train loss: {}\".format(epoch_train_loss))\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    # Put model in evaluation mode to evaluate loss on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss = 0\n",
        "    num_eval_samples = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in valid_dataloader:\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels_r,b_labels_c = batch\n",
        "      # Telling the model not to compute or store gradients,\n",
        "      # saving memory and speeding up validation\n",
        "      with torch.no_grad():\n",
        "        # Forward pass, calculate validation loss\n",
        "        loss = model(b_input_ids, attention_mask=b_input_mask, labels_r=b_labels_r,labels_c=b_labels_c)\n",
        "        eval_loss += loss.item()\n",
        "        num_eval_samples += b_labels_c.size(0)\n",
        "\n",
        "    epoch_eval_loss = eval_loss/num_eval_samples\n",
        "    valid_loss_set.append(epoch_eval_loss)\n",
        "\n",
        "    print(\"Valid loss: {}\".format(epoch_eval_loss))\n",
        "\n",
        "    if lowest_eval_loss == None:\n",
        "      lowest_eval_loss = epoch_eval_loss\n",
        "      # save model\n",
        "      save_model(model, model_save_path, actual_epoch,\\\n",
        "                 lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    else:\n",
        "      if epoch_eval_loss < lowest_eval_loss:\n",
        "        lowest_eval_loss = epoch_eval_loss\n",
        "        # save model\n",
        "        save_model(model, model_save_path, actual_epoch,\\\n",
        "                   lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    print(\"\\n\")\n",
        "\n",
        "  return model, train_loss_set, valid_loss_set\n",
        "\n",
        "\n",
        "def save_model(model, save_path, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist):\n",
        "  \"\"\"\n",
        "  Save the model to the path directory provided\n",
        "  \"\"\"\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model\n",
        "  checkpoint = {'epochs': epochs, \\\n",
        "                'lowest_eval_loss': lowest_eval_loss,\\\n",
        "                'state_dict': model_to_save.state_dict(),\\\n",
        "                'train_loss_hist': train_loss_hist,\\\n",
        "                'valid_loss_hist': valid_loss_hist\n",
        "               }\n",
        "  torch.save(checkpoint, save_path)\n",
        "  print(\"Saving model at epoch {} with validation loss of {}\".format(epochs,\\\n",
        "                                                                     lowest_eval_loss))\n",
        "  return\n",
        "  \n",
        "def load_model(save_path):\n",
        "  \"\"\"\n",
        "  Load the model from the path directory provided\n",
        "  \"\"\"\n",
        "  checkpoint = torch.load(save_path)\n",
        "  model_state_dict = checkpoint['state_dict']\n",
        "  model = ElectraForMultiLabelSequenceClassification(num_labels=model_state_dict[\"classifier.weight\"].size()[0])\n",
        "  model.load_state_dict(model_state_dict)\n",
        "\n",
        "  epochs = checkpoint[\"epochs\"]\n",
        "  lowest_eval_loss = checkpoint[\"lowest_eval_loss\"]\n",
        "  train_loss_hist = checkpoint[\"train_loss_hist\"]\n",
        "  valid_loss_hist = checkpoint[\"valid_loss_hist\"]\n",
        "  \n",
        "  return model, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hdkFFPcEahl"
      },
      "source": [
        "Now we need to define for how many epochs our model will be runing and were we store the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6NoScwbXq4g"
      },
      "source": [
        "num_epochs=20\n",
        "\n",
        "cwd = os.getcwd()\n",
        "model_save_path = output_model_file = os.path.join(cwd, \"drive/MyDrive/SeedDoubleHead_OmlyElectraSharedWeights_20epochs_Electra.bin\")\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U94dlIocUgoG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S83Su9sXEokq"
      },
      "source": [
        "mow we will just train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlYnK3ClXwGf"
      },
      "source": [
        "model, train_loss_set, valid_loss_set = train(model=model,\\\n",
        "                                              num_epochs=num_epochs,\\\n",
        "                                              optimizer=optimizer,\\\n",
        "                                              train_dataloader=train_dataloader,\\\n",
        "                                              valid_dataloader=validation_dataloader,\\\n",
        "                                              model_save_path=model_save_path,\\\n",
        "                                              device=\"cuda\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ssYG_1fFhbm"
      },
      "source": [
        "Now that our model has been trained we will load the best version of the model that acheived the lowes loss on the validation set during the data and use it to predict the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAE_E2o2nbzx",
        "outputId": "c18bd2ed-9d34-4eda-836f-7d7a49e77228"
      },
      "source": [
        "checkpoint = torch.load(model_save_path)\n",
        "model_state_dict = checkpoint['state_dict']\n",
        "model = ElectraSharedWeights_Multi_Task(c_num_labels=4,r_num_labels=5)\n",
        "model.load_state_dict(model_state_dict)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsy_X2WZFzt0"
      },
      "source": [
        "To generate predictions from the results provided by our model for both regression and classification task we define a Predict function that gives us both predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrB3xNiqX8fJ"
      },
      "source": [
        "def Predict(model, features,mask, num_label_c,num_label_r, device=\"cpu\", batch_size=32):\n",
        "  num_iter = math.ceil(features.shape[0]/batch_size)# define the number of iteration in all the data by batches\n",
        "  model.eval() #Indicate that we will use the model to evaluation purposes\n",
        "\n",
        "  c_pred_probs = np.array([]).reshape(0, num_label_c)# Create dummpy classification predictions 'all 0' vectors that we will modify\n",
        "  r_pred_probs = np.array([]).reshape(0, num_label_r)# Create dummpy regression predictions 'all 0' vectors that we will modify\n",
        "  model.to(device)\n",
        "  d={}\n",
        "  \n",
        "  for i in range(num_iter):# for each batch\n",
        "    X = features[i*batch_size:(i+1)*batch_size,:]#Get the features of the passed data\n",
        "    masks = mask[i*batch_size:(i+1)*batch_size,:]#Get the masks of the passed data\n",
        "    X = X.to(device)#transfer them to the device 'exmp cuda'\n",
        "    masks = masks.to(device)#transfer them to the device 'exmp cuda'\n",
        "    with torch.no_grad():\n",
        "      logits_c,logits_r = model(input_ids=X, attention_mask=masks) # predict the values of the passed batch of data\n",
        "      #logits = logits.sigmoid().detach().cpu().numpy()\n",
        "      logits_c = logits_c.sigmoid().detach().cpu().numpy()# for the classification head we will aplly a sigmoid function as like we said the classification labels are binary labels\n",
        "      c_pred_probs = np.vstack([c_pred_probs, logits_c])# stack them to the pr-defined dummy classification variable\n",
        "      logits_r = logits_r.detach().cpu().numpy()# For the regression values wi well use directly the linear layer output because the regression labels are real values\n",
        "      r_pred_probs = np.vstack([r_pred_probs, logits_r])# stack them to the pr-defined dummy regression variable\n",
        "  d['class_pred']=np.round(c_pred_probs) # to get binary values for the sigmoids probability values we will use the .round() function for the classification results\n",
        "  d['reg_pred']=r_pred_probs\n",
        "  \n",
        "  return d\n",
        "  \n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4HU9Wm66_2w"
      },
      "source": [
        "num_labels=len(label_cols)\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYRxE3XwIRpA"
      },
      "source": [
        "####Generate predictions for the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzONqUoSwJU-"
      },
      "source": [
        "pred_probs = Predict(model, test_input_ids,test_attention_masks, 4,5, device=\"cuda\", batch_size=32)\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR7Nwagi9cW5",
        "outputId": "8116e298-1933-44b9-b325-4a375b6fc7d5"
      },
      "source": [
        "pred_probs.keys()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['class_pred', 'reg_pred'])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjmLiAJL9kr7",
        "outputId": "619e557d-0e02-4273-924e-402a34d28348"
      },
      "source": [
        "c_pred_probs=pred_probs['class_pred']\n",
        "c_pred_probs"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1.],\n",
              "       ...,\n",
              "       [1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55Td2kLMdoZr"
      },
      "source": [
        ""
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPuC_Wo1KfiM"
      },
      "source": [
        "Now we will add the predictions classification labels columns for each original label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kllLd8kprqpj"
      },
      "source": [
        "label_cols = ['introverted', 'intuitive', 'thinking', 'perceiving']\n",
        "\n",
        "test[\"pred_introverted\"] = c_pred_probs[:,0]\n",
        "test[\"pred_intuitive\"] = c_pred_probs[:,1]\n",
        "test[\"pred_thinking\"] = c_pred_probs[:,2]\n",
        "test[\"pred_perceiving\"] = c_pred_probs[:,3]\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhXAKDzMIojt"
      },
      "source": [
        "To take a closure look to the classification performance of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "rPcKJNIb-H6e",
        "outputId": "5fb28af5-8774-440e-ef7a-5d2fcd4c9e66"
      },
      "source": [
        "test.drop(['author', 'body','created_utc',\t'agreeableness'\t,'openness'\t,'conscientiousness'\t,'extraversion',\t'neuroticism'],axis=1).head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>introverted</th>\n",
              "      <th>intuitive</th>\n",
              "      <th>thinking</th>\n",
              "      <th>perceiving</th>\n",
              "      <th>pred_introverted</th>\n",
              "      <th>pred_intuitive</th>\n",
              "      <th>pred_thinking</th>\n",
              "      <th>pred_perceiving</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>320807</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562195</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>649370</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023190</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117790</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         introverted  intuitive  ...  pred_thinking  pred_perceiving\n",
              "320807           1.0        1.0  ...            1.0              1.0\n",
              "562195           1.0        1.0  ...            1.0              1.0\n",
              "649370           0.0        0.0  ...            1.0              1.0\n",
              "1023190          1.0        0.0  ...            1.0              1.0\n",
              "117790           1.0        1.0  ...            1.0              1.0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQOyedFkZWWw"
      },
      "source": [
        "real_values=test[label_cols]\n",
        "predicted_values=test[['pred_introverted','pred_intuitive','pred_thinking','pred_perceiving']]"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nLXW6Nnwd1ne",
        "outputId": "0a0d55cf-4e30-4297-bc6d-a2fbadf5f1a6"
      },
      "source": [
        "predicted_values.head()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_introverted</th>\n",
              "      <th>pred_intuitive</th>\n",
              "      <th>pred_thinking</th>\n",
              "      <th>pred_perceiving</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>320807</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562195</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>649370</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023190</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117790</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         pred_introverted  pred_intuitive  pred_thinking  pred_perceiving\n",
              "320807                1.0             1.0            1.0              1.0\n",
              "562195                1.0             1.0            1.0              1.0\n",
              "649370                1.0             1.0            1.0              1.0\n",
              "1023190               0.0             1.0            1.0              1.0\n",
              "117790                1.0             1.0            1.0              1.0"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQgrUcZBK8l0"
      },
      "source": [
        "To evaluate the performance of our classification head we will use different metrics such as f1 score, accuracy, precison etc.. for each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGSK7IEvNBxt"
      },
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "name_columns=real_values.columns.values\n",
        "metrics={}\n",
        "metrics[\"accuracy_score\"]=accuracy_score\n",
        "metrics[\"precision_score\"]=precision_score\n",
        "metrics[\"recall_score\"]=recall_score\n",
        "metrics[\"f1_score\"]=f1_score\n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpdFLJD-pgwN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJowQfxZNuO_"
      },
      "source": [
        "test_evaluation_values={}\n",
        "for column in name_columns:\n",
        "    test_evaluation_values[str(column)]=[]"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG3s8MYPN1Xt"
      },
      "source": [
        "for k,v in  metrics.items():\n",
        "  for column in name_columns:\n",
        "    test_evaluation_values[str(column)].append(v(real_values[column].values,predicted_values[\"pred_\"+str(column)].values))\n",
        "\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF7SAy2hN8mt"
      },
      "source": [
        "d=pd.DataFrame(data=test_evaluation_values,index=list(metrics.keys())).T # F1 score, recall is always better\n",
        "avg=[]\n",
        "avg=[d['accuracy_score'].mean(),d['precision_score'].mean(),d['recall_score'].mean(),d['f1_score'].mean()]\n",
        "d=d.append(dict(zip(d.columns,avg)), ignore_index=True)\n",
        "d.index=list(name_columns)+['avg']"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Mp5ENsxbdlVE",
        "outputId": "0dec4b88-86ab-4bc6-ddb1-4a5c98c7c9c3"
      },
      "source": [
        "d"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_score</th>\n",
              "      <th>precision_score</th>\n",
              "      <th>recall_score</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>introverted</th>\n",
              "      <td>0.648300</td>\n",
              "      <td>0.675554</td>\n",
              "      <td>0.906102</td>\n",
              "      <td>0.774025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intuitive</th>\n",
              "      <td>0.913139</td>\n",
              "      <td>0.913139</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.954598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thinking</th>\n",
              "      <td>0.768833</td>\n",
              "      <td>0.768833</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.869311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perceiving</th>\n",
              "      <td>0.610992</td>\n",
              "      <td>0.610992</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.758529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avg</th>\n",
              "      <td>0.735316</td>\n",
              "      <td>0.742129</td>\n",
              "      <td>0.976525</td>\n",
              "      <td>0.839116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             accuracy_score  precision_score  recall_score  f1_score\n",
              "introverted        0.648300         0.675554      0.906102  0.774025\n",
              "intuitive          0.913139         0.913139      1.000000  0.954598\n",
              "thinking           0.768833         0.768833      1.000000  0.869311\n",
              "perceiving         0.610992         0.610992      1.000000  0.758529\n",
              "avg                0.735316         0.742129      0.976525  0.839116"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUmCg0YNLXGR"
      },
      "source": [
        "We can see that our model is doing much better comparing to state of the art models baselines on this dataset.\n",
        "\n",
        "https://paperswithcode.com/dataset/pandora\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "iynOnRxceO5Y",
        "outputId": "655cb59a-715d-4cb9-f1ea-f08182e1d2ea"
      },
      "source": [
        "#all shaerd saved model\n",
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_score</th>\n",
              "      <th>precision_score</th>\n",
              "      <th>recall_score</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>introverted</th>\n",
              "      <td>0.666954</td>\n",
              "      <td>0.668361</td>\n",
              "      <td>0.996568</td>\n",
              "      <td>0.800115</td>\n",
              "      <td>0.498862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intuitive</th>\n",
              "      <td>0.907734</td>\n",
              "      <td>0.907734</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.951636</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thinking</th>\n",
              "      <td>0.763333</td>\n",
              "      <td>0.763333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.865784</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perceiving</th>\n",
              "      <td>0.563400</td>\n",
              "      <td>0.592649</td>\n",
              "      <td>0.896310</td>\n",
              "      <td>0.713515</td>\n",
              "      <td>0.473200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avg</th>\n",
              "      <td>0.725355</td>\n",
              "      <td>0.733019</td>\n",
              "      <td>0.973219</td>\n",
              "      <td>0.832762</td>\n",
              "      <td>0.493015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             accuracy_score  precision_score  ...  f1_score  roc_auc_score\n",
              "introverted        0.666954         0.668361  ...  0.800115       0.498862\n",
              "intuitive          0.907734         0.907734  ...  0.951636       0.500000\n",
              "thinking           0.763333         0.763333  ...  0.865784       0.500000\n",
              "perceiving         0.563400         0.592649  ...  0.713515       0.473200\n",
              "avg                0.725355         0.733019  ...  0.832762       0.493015\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCvoUjpcLmnV"
      },
      "source": [
        "#Evaluating the regression head "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO6FFd4qLrvD"
      },
      "source": [
        "like we said our prediction method produce two different predictions. The classification prediction that we evaluated it above and the regression predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcTwpgVD92le",
        "outputId": "c16efbd7-3d65-4efe-ed1e-eab2d5c45489"
      },
      "source": [
        "r_pred_probs=pred_probs['reg_pred']\n",
        "r_pred_probs"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40.47015381, 66.40448761, 41.4925766 , 36.64008331, 35.2992897 ],\n",
              "       [43.52455521, 67.58790588, 45.7296257 , 38.35994339, 32.94988632],\n",
              "       [29.68279266, 68.52210999, 24.26068687, 34.07448578, 53.85827255],\n",
              "       ...,\n",
              "       [31.70005226, 62.95755386, 30.34681702, 30.55232811, 42.1090889 ],\n",
              "       [47.86090088, 75.17791748, 46.73184967, 48.37638855, 40.24618149],\n",
              "       [26.96555519, 61.33392715, 23.00028229, 31.9671936 , 46.79043198]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpGeGfLZMGK7"
      },
      "source": [
        "Now we will add the predictions regression labels columns for each original label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez1wjZNwAdep"
      },
      "source": [
        "label_cols = [\"agreeableness\",\t\"openness\",\t\"conscientiousness\",\t\"extraversion\",\t\"neuroticism\"]\n",
        "\n",
        "test[\"pred_agreeableness\"] = r_pred_probs[:,0]\n",
        "test[\"pred_openness\"] = r_pred_probs[:,1]\n",
        "test[\"pred_conscientiousness\"] = r_pred_probs[:,2]\n",
        "test[\"pred_extraversion\"] = r_pred_probs[:,3]\n",
        "test[\"pred_neuroticism\"] = r_pred_probs[:,4]\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "0xKJkRr0Adep",
        "outputId": "8ae58726-d769-470e-c284-78899e6fc62c"
      },
      "source": [
        "test.drop(['author','created_utc','introverted',\t'intuitive',\t'thinking',\t'perceiving','pred_introverted',\t'pred_intuitive',\t'pred_thinking',\t'pred_perceiving'],axis=1).head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>body</th>\n",
              "      <th>agreeableness</th>\n",
              "      <th>openness</th>\n",
              "      <th>conscientiousness</th>\n",
              "      <th>extraversion</th>\n",
              "      <th>neuroticism</th>\n",
              "      <th>pred_agreeableness</th>\n",
              "      <th>pred_openness</th>\n",
              "      <th>pred_conscientiousness</th>\n",
              "      <th>pred_extraversion</th>\n",
              "      <th>pred_neuroticism</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>320807</th>\n",
              "      <td>Luckily I find that other women are more than ...</td>\n",
              "      <td>98.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>40.470154</td>\n",
              "      <td>66.404488</td>\n",
              "      <td>41.492577</td>\n",
              "      <td>36.640083</td>\n",
              "      <td>35.299290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562195</th>\n",
              "      <td>[Here](http://www.virtualbattlemap.com/) ya go...</td>\n",
              "      <td>78.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>43.524555</td>\n",
              "      <td>67.587906</td>\n",
              "      <td>45.729626</td>\n",
              "      <td>38.359943</td>\n",
              "      <td>32.949886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>649370</th>\n",
              "      <td>Washington, UCF, K-State, Colorado, Pitt in no...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.682793</td>\n",
              "      <td>68.522110</td>\n",
              "      <td>24.260687</td>\n",
              "      <td>34.074486</td>\n",
              "      <td>53.858273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023190</th>\n",
              "      <td>Doot doot</td>\n",
              "      <td>90.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>23.846178</td>\n",
              "      <td>62.255493</td>\n",
              "      <td>18.226322</td>\n",
              "      <td>33.040768</td>\n",
              "      <td>53.325684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117790</th>\n",
              "      <td>Hm, so up until a certain point, both old and ...</td>\n",
              "      <td>45.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>32.988369</td>\n",
              "      <td>59.293369</td>\n",
              "      <td>33.812134</td>\n",
              "      <td>25.924055</td>\n",
              "      <td>34.481518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      body  ...  pred_neuroticism\n",
              "320807   Luckily I find that other women are more than ...  ...         35.299290\n",
              "562195   [Here](http://www.virtualbattlemap.com/) ya go...  ...         32.949886\n",
              "649370   Washington, UCF, K-State, Colorado, Pitt in no...  ...         53.858273\n",
              "1023190                                          Doot doot  ...         53.325684\n",
              "117790   Hm, so up until a certain point, both old and ...  ...         34.481518\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqbfose3Adep"
      },
      "source": [
        "real_values=test[label_cols]\n",
        "label_cols = [\"agreeableness\",\t\"openness\",\t\"conscientiousness\",\t\"extraversion\",\t\"neuroticism\"]\n",
        "\n",
        "predicted_values=test[['pred_agreeableness','pred_openness','pred_conscientiousness','pred_extraversion','pred_neuroticism']]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCpF-ArEM0Lw"
      },
      "source": [
        "Due to the fact that onl the original paper of the Pandora dataset had tried to rpedict the label values of the BIG5 as a regression task we will evaluate our model comparing to the metric that they used duringthe evaluation prosess. In this paper the authors used the person correlation metric to compute the correlation between the original regression labels and the predicted labels and they score a 0.3 correlation. Thats why we will use the person correlation metric to evaluate the performance of our model comparing to the performance of this paper models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLz8ByZrNsuq",
        "outputId": "b47e296b-88d2-4695-95f7-5b22d423d065"
      },
      "source": [
        "#qll shqred\n",
        "audtorch.metrics.functional.pearsonr(torch.tensor(real_values.values), torch.tensor(predicted_values.values), batch_first=True).mean()\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4694, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsiNNrlmNtXI"
      },
      "source": [
        "we acheivef a 0.469 correlation between the predicted and the original values which overpass the value provided by the state of the art basline for the Pandora datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0lzXTO_N676"
      },
      "source": [
        ""
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cvq91BhN7VG"
      },
      "source": [
        "To more investigate the perfomance of our model we used different other metrics such as mean square error, r2 score, the mean absolute error etc.. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep69erTTAdeq"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error,max_error,mean_absolute_error,mean_squared_log_error,median_absolute_error,r2_score\n",
        "name_columns=real_values.columns.values\n",
        "metrics={}\n",
        "metrics[\"mean_squared_error\"]=mean_squared_error\n",
        "metrics[\"max_error\"]=max_error\n",
        "metrics[\"mean_absolute_error\"]=mean_absolute_error\n",
        "metrics[\"mean_squared_log_error\"]=mean_squared_log_error\n",
        "metrics[\"median_absolute_error\"]=median_absolute_error\n",
        "metrics[\"r2_score\"]=r2_score\n",
        "\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NDe008MAdeq"
      },
      "source": [
        "test_evaluation_values={}\n",
        "for column in name_columns:\n",
        "    test_evaluation_values[str(column)]=[]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYziic1RAdeq"
      },
      "source": [
        "for k,v in  metrics.items():\n",
        "  for column in name_columns:\n",
        "    if column !='person r correlation':\n",
        "      test_evaluation_values[str(column)].append(v(real_values[column].values,predicted_values[\"pred_\"+str(column)].values))\n",
        "    else:\n",
        "      test_evaluation_values[str(column)].append(v(real_values[[column]].values,predicted_values[[\"pred_\"+str(column)]].values).mean())\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LvBIP8bAdeq"
      },
      "source": [
        "d=pd.DataFrame(data=test_evaluation_values,index=list(metrics.keys())).T # F1 score, recall is always better\n",
        "avg=[]\n",
        "avg=[d['mean_squared_error'].mean(),d['max_error'].mean(),d['mean_absolute_error'].mean(),d['mean_squared_log_error'].mean(),d['median_absolute_error'].mean(),d['r2_score'].mean()]\n",
        "d=d.append(dict(zip(d.columns,avg)), ignore_index=True)\n",
        "d.index=list(name_columns)+['avg']"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "q3ilWUqtSMvZ",
        "outputId": "bf5bc4a1-80d6-47d7-cb92-8374971475f6"
      },
      "source": [
        "#saved model shared weights\n",
        "d"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>max_error</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>mean_squared_log_error</th>\n",
              "      <th>median_absolute_error</th>\n",
              "      <th>r2_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>agreeableness</th>\n",
              "      <td>882.814831</td>\n",
              "      <td>79.006084</td>\n",
              "      <td>25.573411</td>\n",
              "      <td>1.792167</td>\n",
              "      <td>23.597282</td>\n",
              "      <td>0.038895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>openness</th>\n",
              "      <td>535.316759</td>\n",
              "      <td>83.240517</td>\n",
              "      <td>18.829544</td>\n",
              "      <td>0.276530</td>\n",
              "      <td>17.648758</td>\n",
              "      <td>-0.006352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conscientiousness</th>\n",
              "      <td>948.015190</td>\n",
              "      <td>81.123352</td>\n",
              "      <td>25.685431</td>\n",
              "      <td>1.722717</td>\n",
              "      <td>21.957897</td>\n",
              "      <td>0.065252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extraversion</th>\n",
              "      <td>902.290094</td>\n",
              "      <td>73.727119</td>\n",
              "      <td>26.240673</td>\n",
              "      <td>2.034806</td>\n",
              "      <td>25.509546</td>\n",
              "      <td>0.062167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neuroticism</th>\n",
              "      <td>984.780675</td>\n",
              "      <td>67.711531</td>\n",
              "      <td>27.752496</td>\n",
              "      <td>1.247513</td>\n",
              "      <td>28.652016</td>\n",
              "      <td>0.053905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avg</th>\n",
              "      <td>850.643510</td>\n",
              "      <td>76.961721</td>\n",
              "      <td>24.816311</td>\n",
              "      <td>1.414746</td>\n",
              "      <td>23.473100</td>\n",
              "      <td>0.042773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   mean_squared_error  ...  r2_score\n",
              "agreeableness              882.814831  ...  0.038895\n",
              "openness                   535.316759  ... -0.006352\n",
              "conscientiousness          948.015190  ...  0.065252\n",
              "extraversion               902.290094  ...  0.062167\n",
              "neuroticism                984.780675  ...  0.053905\n",
              "avg                        850.643510  ...  0.042773\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwOrWt6WTFjv"
      },
      "source": [
        "\n",
        "import pickle\n",
        "with open ('doubleheadModel.pickle','wb') as f:\n",
        "  pickle.dump(model,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_ThGHyoSQN6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}